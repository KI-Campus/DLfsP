{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLfsP SimpleRNN am Beispiel PSF\n",
    "Kurs Deep Learning für sequentielle Prozessdaten\n",
    "\n",
    "#### In diesem Notebook wird ein einfaches Rekurrentes Neuronales Netz mit TensorFlow auf Zeitreihendaten einer Profilschienenführung (PSF) angewendet. \n",
    "\n",
    "Linearführungen und Profilschienenführungen sind für einen nicht unbedeutenden Teil der Ausfälle bei Werkzeugmaschinen.\n",
    "Typische Fehlerfälle die dabei auftreten sind Mangelschmierungen, Pittings an Laufbahnen oder an den Wälzkörpern. In diesem Beispiel gibt es Daten von Normalfahrten und vom Zustand Pitting.  \n",
    "\n",
    "Während der Versuche wurde mittels einem 3-achsigen MEMS-Sensor Daten vom Wagen aufgenommen. \n",
    "Für diese Aufgabe wurde nur die Beschleunigung in Verfahrrichtung (Acc_X) verwendet. Ziel ist die Erkennung, also Klassifikation nach dem Zustand ('Status').  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-Mining-Prozess:\n",
    "![Daten erfassen -> Daten erkunden -> Daten vorbereiten -> Modelle bilden -> Modelle validieren -> Modell testen & anwenden](Prozess_Modellentwicklung_v2.png \"model development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import der wichtigsten Pakete. '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Überprüfe, ob TensorFlow installiert ist und die GPU oder die CPU nutzt. '''\n",
    "print('TF version: ' + tf.__version__)\n",
    "if tf.test.is_built_with_gpu_support():\n",
    "    if len(tf.config.list_physical_devices('GPU'))==0:\n",
    "         print('Achtung, TensorFlow nutzt gerade die CPU und nicht die GPU!')\n",
    "    else:\n",
    "        print('Default GPU Device: {}'.format(tf.config.list_physical_devices('GPU')))\n",
    "        # GPU-Memory-Management:\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.compat.v1.Session(config=config)\n",
    "else:\n",
    "    print('TensorFlow CPU version active')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "Damit Ergebnisse Reproduzierbar sind, müssen mehrere Seeds für Zufallszahlengeneratoren gesetzt werden. \n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Setzen von Seeds, um Reproduzierbarkeit zu ermöglichen. '''\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))\n",
    "\n",
    "# Seeds für diverse Zufallszahlengeneratoren setzen \n",
    "os.environ['PYTHONHASHSEED']=str(my_seed)\n",
    "tf.random.set_seed(my_seed)\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten erfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PSF_Pitting_kurz.csv') \n",
    "print('Daten erfolgreich importiert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ersten Datensätze als Beispiel\"\"\"\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Statistische Beschreibung Datensatz\"\"\"\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einige Zyklen plotten\n",
    "cycles=[]\n",
    "cycles = random.sample(df['run_ID'].drop_duplicates().to_list(),3)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.ylabel('Beschleunigung in X')\n",
    "for c in cycles:\n",
    "    status = df[df['run_ID']==c].reset_index().loc[0,'Status']\n",
    "    plt.plot(df[df['run_ID']==c]['time_ms'],df[df['run_ID']==c]['Acc_X'],label='Run '+str(c) + ' Status ' + str(status))\n",
    "\n",
    "plt.xlabel('Zeit in ms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Berechnung der No Information Rate (NIR)'''\n",
    "# Anzahl der Fälle je Klasse\n",
    "print('Klasse 0:\\t' + str(len(df[df['Status']==0]['run_ID'].unique())))\n",
    "print('Klasse 1:\\t' + str(len(df[df['Status']==1]['run_ID'].unique())))\n",
    "\n",
    "# No Information Rate:\n",
    "# Dumme Schätzung, immer größte Klasse\n",
    "# NIR = Anzahl Beispiele größte Klasse / Anzahl Beispiele gesamt\n",
    "\n",
    "print('NIR:\\t\\t' + str(round(len(df[df['Status']==0]['run_ID'].unique()) / len(df['run_ID'].unique()), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aufteilung in X und y\"\"\"\n",
    "# Maximale Zykluslänge\n",
    "maxlen = df['run_ID'].value_counts().max()    \n",
    "\n",
    "# Aufteilung X und y Daten als DataFrames\n",
    "y_df = df[['Status','run_ID']]\n",
    "X_df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Umwandeln der DataFrames in numpy arrays und group by run_ID\"\"\"\n",
    "g = X_df.groupby('run_ID').cumcount()\n",
    "X = (X_df.set_index(['run_ID',g])\n",
    "     .unstack()\n",
    "     .stack().groupby(level=0)\n",
    "     .apply(lambda x: x['Acc_X'].values)\n",
    "     .to_numpy())\n",
    "g = y_df.groupby('run_ID').cumcount()\n",
    "y = (y_df.set_index(['run_ID',g])\n",
    "     .unstack()\n",
    "     .stack().groupby(level=0)\n",
    "     .apply(lambda x: np.rint(x.sum()/len(x)))\n",
    "     .to_numpy().astype(\"int32\"))\n",
    "\n",
    "print('Shapes der numpy Arrays X und y:')\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Auffüllen der ungleichen Messreihen'''\n",
    "# Auffüllen mit führenden Nullen, damit die Zeitreihen die gleiche Länge haben\n",
    "X_pre = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=maxlen, padding='pre', dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aufteilen in Trainings-, Validierungs und Testdaten. \"\"\"\n",
    "# Festlegen des Anteils an Test- und Validierungsdaten\n",
    "test_split = 0.2\n",
    "validation_split = 0.2\n",
    "\n",
    "# Aufteilung der Daten\n",
    "# Testdaten abspalten# Aufteilung der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pre, y, \n",
    "                                                    test_size=test_split, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=my_seed)\n",
    "\n",
    "# Aufsplitten in Trainings- und Validierungsdaten\n",
    "X_train, X_val, y_train ,y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=validation_split, \n",
    "                                                  shuffle=True, \n",
    "                                                  random_state=my_seed)\n",
    "\n",
    "nr_train=len(X_train)\n",
    "nr_val=len(X_val)\n",
    "nr_test=len(X_test)\n",
    "print(nr_train, \"Training sequences\")\n",
    "print(nr_val, \"Validation sequences\")\n",
    "print(nr_test, \"Test sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Daten normalisieren. \"\"\"\n",
    "# Importieren und Anlernen des Scalers (d.h. Scaler lernt Mittelwerte und Standardabweichungen der Features)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Normierung der Daten mit den gelernten Paramatern und gleichzeitiges Formatieren\n",
    "X_train = scaler.transform(np.vstack(X_train)).reshape(nr_train, maxlen, -1)\n",
    "X_val = scaler.transform(np.vstack(X_val)).reshape(nr_val, maxlen, -1)\n",
    "X_test = scaler.transform(np.vstack(X_test)).reshape(nr_test, maxlen, -1)\n",
    "print('Datenvorbereitung fertig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Überprüfen der Form der Numpy Arrays. '''\n",
    "print('Shape X_train:\\t' + str(X_train.shape))\n",
    "print('Shape X_val:\\t' + str(X_val.shape))\n",
    "print('Shape X_test:\\t' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelle bilden - Dense Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Dense Modell erstellen\n",
    "\n",
    "Als Baseline wird zuerst ein Dense Modell erstellt, wessen Performance danach mit dem des RNNs verglichen werden kann.\n",
    "\n",
    "TODO:\n",
    "* Importiere den notwendigen Layer\n",
    "* Zunächst muss die Modellstruktur definiert werden. \n",
    "* Die Anzahl der Layer und die Anzahl der Knoten/Nodes pro Layer ist einem selbst überlassen. \n",
    "* Probiere also verschiedene Modellgrößen aus, um das beste Modell für die Aufgabe zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Modellaufbau'''\n",
    "# Import der notwendigen Klassen und Funktionen\n",
    "TODO\n",
    "\n",
    "# Konvertieren der Daten für das Dense Modell\n",
    "# d.h. Flatten der Daten in 1D Tensoren\n",
    "X_train_dense = X_train.reshape(nr_train, -1)\n",
    "X_val_dense = X_val.reshape(nr_val, -1)\n",
    "X_test_dense = X_test.reshape(nr_test, -1)\n",
    "\n",
    "''' Überprüfen der Form der Numpy Arrays. '''\n",
    "print('Shape X_train:\\t' + str(X_train_dense.shape))\n",
    "print('Shape X_val:\\t' + str(X_val_dense.shape))\n",
    "print('Shape X_test:\\t' + str(X_test_dense.shape))\n",
    "\n",
    "\n",
    "# Definition des Input_Shapes\n",
    "input_shape = (maxlen,)\n",
    "\n",
    "# Definition des Modells\n",
    "model=Sequential()\n",
    "\"\"\"\n",
    "*\n",
    "* TODO: \n",
    "*      Dense Layers hinzufügen\n",
    "*      Achtung auf passende Output Layer achten!\n",
    "*\n",
    "\"\"\"\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Modellkompilierung\n",
    "TODO: \n",
    "* Bestimme, welche Loss Funktion verwendet werden soll. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modell kompilieren. '''\n",
    "# Optimizer festlegen\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Einstellung für das spätere Training zum Kompilieren festlegen\n",
    "model.compile(optimizer=optimizer, loss=TODO, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Trainieren des Dense Modells\n",
    "\n",
    "TODO:\n",
    "* Wähle die Anzahl der Epochen aus, für die das Modell trainiert werden soll. \n",
    "* Danach müssen die Trainingsinputs, -outputs sowie die Validierungsdaten bestimmt werden.\n",
    "\n",
    "Ausgabe: \n",
    "* Zwischenergebnisse je Epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Modell trainieren '''\n",
    "# Festlegung der Batch_Size und Anzahl der Epoche\n",
    "batch_size = 32\n",
    "epochs = TODO\n",
    "\n",
    "# Durchführen des Trainings. Die Ergebnisse je Epoche werden in der History gespeichert. \n",
    "history = model.fit(x=TODO, y=TODO, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(TODO, TODO), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelle validieren - Dense Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennzahlen fürs Training und Validierung:\n",
    "Übergeben Sie der Evaluate Methode die Validierungdaten zur Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kennzahlen (Loss und Accuracy Metrik) fürs Training beim Dense Modell:')\n",
    "print(model.evaluate(X_train_dense, y_train))\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) für Validierung beim Dense Modell:')\n",
    "print(model.evaluate(X_val_dense, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trainingsverlauf plotten. \"\"\"\n",
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(train_acc) +1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_acc,'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc,'b', label='Validation accuracy')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(top=1.0)  # adjust the top leaving bottom unchanged\n",
    "plt.title('Loss Dense NN', fontsize = 16)\n",
    "plt.title('Accuracy', fontsize=16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(bottom=0.0)  \n",
    "plt.title('Loss Dense NN', fontsize = 16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelle bilden - Simple RNN\n",
    "\n",
    "### 1. Modellaufbau - Simple RNN\n",
    "\n",
    "TODO:\n",
    "* Importiere die notwendigen Layer\n",
    "* Definiere die Modellstruktur \n",
    "* Die Anzahl der Layer und die Anzahl der Knoten/Nodes pro Layer ist einem selbst überlassen. \n",
    "* Probiere verschiedene Modellgrößen aus, um das beste Modell für die Aufgabe zu finden.\n",
    "\n",
    "Achtung:  \n",
    "Dieses Problem ist etwas komplexer, daher rate ich hier zu zwei Schichten von SimpleRNN Layern. \n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modellaufbau '''\n",
    "# Import der notwendigen Layer\n",
    "TODO\n",
    "\n",
    "feature_number = 1\n",
    "input_shape = (maxlen, feature_number)\n",
    "\n",
    "\"\"\"Model\"\"\"\n",
    "\n",
    "model=Sequential()\n",
    "\"\"\"\n",
    "*\n",
    "* TODO: \n",
    "*      Dense Layers hinzufügen\n",
    "*      Achtung auf passende Output Layer achten!\n",
    "*\n",
    "\"\"\"\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Modellkompellieren - SimpleRNN \n",
    "\n",
    "TODO: \n",
    "* Bestimme, welche Loss Funktion verwendet werden soll. \n",
    "\n",
    "Optional:  \n",
    "* Teste unterschiedliche Lernraten oder verwende auch mal einen anderen Optimierer\n",
    "\n",
    "Hinweise:  \n",
    "Die Lernrate ist ein sehr wichtiger Hyperparameter, der viel Einfluss auf den Verlauf und Schnelligkeit des Trainings hat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modell kompilieren. '''\n",
    "# Optimizer festlegen\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Einstellung für das spätere Training zum Kompilieren festlegen\n",
    "model.compile(optimizer=optimizer, loss=TODO, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Modelltraining - SimpleRNN\n",
    "\n",
    "TODO:\n",
    "* Wähle die Anzahl der Epochen aus, für die das Modell trainiert werden soll. \n",
    "* Danach müssen die Trainingsinputs, -outputs sowie die Validierungsdaten bestimmt werden.\n",
    "\n",
    "Ausgabe: \n",
    "* Zwischenergebnisse je Epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modell trainieren '''\n",
    "# Festlegung der Batch_Size und Anzahl der Epoche\n",
    "epochs=TODO\n",
    "batch_size=32\n",
    "\n",
    "# Durchführen des Trainings. Die Ergebnisse je Epoche werden in der History gespeichert. \n",
    "history = model.fit(x=TODO, y=TODO, batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=(TODO, TODO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelle validieren - SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennzahlen fürs Training und Validierung:\n",
    "TODO:\n",
    "* Übergebe jeweils die Trainingsdaten bzw. Validierungsdaten dem evaluate Befehl. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Bewertung des Trainings anhand der Valididierungsdaten mittels der Accuracy. '''\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) fürs Training:')\n",
    "print(model.evaluate(TODO, TODO))\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) für Validierung:')\n",
    "print(model.evaluate(TODO, TODO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trainingsverlauf plotten. \"\"\"\n",
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(train_acc) +1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_acc,'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc,'b', label='Validation accuracy')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(top=1.0)  # adjust the top leaving bottom unchanged\n",
    "plt.title('Accuracy SimpleRNN', fontsize=16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(bottom=0.0)  \n",
    "plt.title('Loss SimpleRNN', fontsize = 16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modell testen & anwenden\n",
    "\n",
    "Führen Sie diesen Schritt erst aus, wenn Sie mit Ihrem Modell zufrieden sind.  \n",
    "\n",
    "Der Test eines Modells soll ermitteln, wie gut das Modell übertragbar und generalisierbar ist.  \n",
    "Wenn Sie alle Modelle direkt testen, wählen Sie nur das Modell aus, was am Besten zum Testdatensatz passt. Aber nicht welches das Problem grundsätzlich am Besten löst. Sie Overfitten somit den Testdatensatz.\n",
    "\n",
    "TODO:\n",
    "* Übergebe die Testdaten dem evaluate Befehl zur finalen Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Bewertung des Trainings anhand der Valididierungsdaten mittels der Accuracy. '''\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) bei Testen:')\n",
    "model.evaluate(TODO,TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Modell anhand Testdaten bewerten\"\"\"\n",
    "y_test_pred = (model.predict(X_test)>0.5).astype(\"int32\")\n",
    "# Berechne Genauigkeit auf den Testdaten\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Berechne den F1-Score auf den Testdaten\n",
    "f1score_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für den Test:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_test, 4)))\n",
    "print('F1-Score: \\t' + str(round(f1score_test, 4)))\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "plt.grid()\n",
    "plt.title('Konfusionsmatrix auf Testdaten')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bonus Shuffle der Daten\n",
    "Um mit den geshuffleten (durchgemischte, permutierte) Daten ein neues Modell zu trainieren, führe die nachfolgenden Code-Zellen aus. \n",
    "Dann ersetze in der Code-Zelle \"Aufteilen in Trainings-, Validierungs und Testdaten.\" in der 8. Zeile den Ausdruck \"X_pre\"  durch X_shuffle. Führe danach die Code-Zelle \"Aufteilen in Trainings-, Validierungs und Testdaten.\" und alle folgenden Zellen mit dem Training und Validierung der Modelle aus, um ein neues Modell mit den geshuffelten Daten zu bekommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" shuffle cycles with a random permutation \"\"\"\n",
    "shuffled_indices = np.random.permutation(maxlen)\n",
    "X_shuffle = np.array([x[shuffled_indices[shuffled_indices<len(X_pre)]] for x in X_pre], dtype='float32')\n",
    "print('Zeitschritte zufällig durchmischt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Visualisierung bevor und nach Durchmischung. '''\n",
    "run = random.randint(0,155)\n",
    "tmp_run = X_pre[run]\n",
    "tmp_run_shuffle = X_shuffle[run]\n",
    "\n",
    "plt.figure(figsize=(12 ,8))\n",
    "plt.title('Beschleunigung in X',fontsize = 16)\n",
    "plt.plot(tmp_run[:][tmp_run[:]!=0],'-ob', label='Run '+str(run))\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Beschleunigung in X',fontsize = 16)\n",
    "plt.plot(tmp_run_shuffle[:][tmp_run_shuffle[:]!=0],'-ob', label='shuffled run '+str(run))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DLfsP)",
   "language": "python",
   "name": "python-dlfsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
