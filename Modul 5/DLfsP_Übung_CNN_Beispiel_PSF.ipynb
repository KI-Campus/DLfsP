{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLfsP CNN am Beispiel PSF\n",
    "Kurs Deep Learning für sequentielle Prozessdaten\n",
    "\n",
    "#### In diesem Notebook werden CNN Layer auf Zeitreihendaten einer Profilschienenführung (PSF) angewendet. \n",
    "\n",
    "Linearführungen und Profilschienenführungen sind für einen nicht unbedeutenden Teil der Ausfälle bei Werkzeugmaschinen.\n",
    "Typische Fehlerfälle die dabei auftreten sind Mangelschmierungen, Pittings an Laufbahnen oder an den Wälzkörpern. In diesem Beispiel gibt es Daten von Normalfahrten und vom Zustand Pitting.  \n",
    "\n",
    "Während der Versuche wurde mittels einem 3-achsigen MEMS-Sensor Daten vom Wagen aufgenommen. \n",
    "Für diese Aufgabe wurde nur die Beschleunigung in Verfahrrichtung (Acc_X) verwendet. Grundsätzlich handelt es sich um die gleichen Daten wie beim SimpleRNN, allerdings wurden nun längere Zeitreihen mit einer höheren Genauigkeit aufgenommen. Ziel ist die Erkennung, also Klassifikation nach dem Zustand ('Status'). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-Mining-Prozess:\n",
    "![Daten erfassen -> Daten erkunden -> Daten vorbereiten -> Modelle bilden -> Modelle validieren -> Modell testen & anwenden](Prozess_Modellentwicklung_v2.png \"model development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import der wichtigsten Pakete. '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Überprüfe, ob TensorFlow installiert ist und die GPU oder die CPU nutzt. '''\n",
    "print('TF version: ' + tf.__version__)\n",
    "if tf.test.is_built_with_gpu_support():\n",
    "    if len(tf.config.list_physical_devices('GPU'))==0:\n",
    "         print('Achtung, TensorFlow nutzt gerade die CPU und nicht die GPU!')\n",
    "    else:\n",
    "        print('Default GPU Device: {}'.format(tf.config.list_physical_devices('GPU')))\n",
    "        # GPU-Memory-Management:\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.compat.v1.Session(config=config)\n",
    "else:\n",
    "    print('TensorFlow CPU version active')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "Damit Ergebnisse Reproduzierbar sind, müssen mehrere Seeds für Zufallszahlengeneratoren gesetzt werden. \n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Setzen von Seeds, um Reproduzierbarkeit zu ermöglichen. '''\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))\n",
    "\n",
    "# Seeds für diverse Zufallszahlengeneratoren setzen \n",
    "os.environ['PYTHONHASHSEED']=str(my_seed)\n",
    "tf.random.set_seed(my_seed)\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten erfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PSF_Pitting.csv') \n",
    "print('Daten erfolgreich importiert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ersten Datensätze als Beispiel\"\"\"\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Statistische Beschreibung Datensatz\"\"\"\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einige Zyklen plotten\n",
    "cycles=[]\n",
    "cycles = random.sample(df['run_ID'].drop_duplicates().to_list(),3)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.ylabel('Beschleunigung in X')\n",
    "for c in cycles:\n",
    "    status = df[df['run_ID']==c].reset_index().loc[0,'Status']\n",
    "    plt.plot(df[df['run_ID']==c]['time_ms'],df[df['run_ID']==c]['Acc_X'],label='Run '+str(c) + ' Status ' + str(status))\n",
    "\n",
    "plt.xlabel('Zeit in ms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aufteilung in X und y\"\"\"\n",
    "# Maximale Zykluslänge\n",
    "maxlen = df['run_ID'].value_counts().max()    \n",
    "\n",
    "# Aufteilung X und y Daten als DataFrames\n",
    "y_df = df[['Status','run_ID']]\n",
    "X_df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Umwandeln der DataFrames in numpy arrays und group by run_ID\"\"\"\n",
    "g = X_df.groupby('run_ID').cumcount()\n",
    "X = (X_df.set_index(['run_ID',g])\n",
    "     .unstack()\n",
    "     .stack().groupby(level=0)\n",
    "     .apply(lambda x: x['Acc_X'].values)\n",
    "     .to_numpy())\n",
    "g = y_df.groupby('run_ID').cumcount()\n",
    "y = (y_df.set_index(['run_ID',g])\n",
    "     .unstack()\n",
    "     .stack().groupby(level=0)\n",
    "     .apply(lambda x: np.rint(x.sum()/len(x)))\n",
    "     .to_numpy().astype(\"int32\"))\n",
    "\n",
    "print('Shapes der numpy Arrays X und y:')\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Auffüllen der ungleichen Messreihen'''\n",
    "# Auffüllen mit führenden Nullen, damit die Zeitreihen die gleiche Länge haben\n",
    "X_pre = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=maxlen, padding='pre', dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aufteilen in Trainings-, Validierungs und Testdaten. \"\"\"\n",
    "# Festlegen des Anteils an Test- und Validierungsdaten\n",
    "test_split = 0.2\n",
    "validation_split = 0.2\n",
    "\n",
    "# Aufteilung der Daten\n",
    "# Testdaten abspalten# Aufteilung der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pre, y, \n",
    "                                                    test_size=test_split, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=my_seed)\n",
    "\n",
    "# Aufsplitten in Trainings- und Validierungsdaten\n",
    "X_train, X_val, y_train ,y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=validation_split, \n",
    "                                                  shuffle=True, \n",
    "                                                  random_state=my_seed)\n",
    "\n",
    "nr_train=len(X_train)\n",
    "nr_val=len(X_val)\n",
    "nr_test=len(X_test)\n",
    "print(nr_train, \"Training sequences\")\n",
    "print(nr_val, \"Validation sequences\")\n",
    "print(nr_test, \"Test sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Daten normalisieren. \"\"\"\n",
    "# Importieren und Anlernen des Scalers (d.h. Scaler lernt Mittelwerte und Standardabweichungen der Features)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Normierung der Daten mit den gelernten Paramatern und gleichzeitiges Formatieren\n",
    "X_train = scaler.transform(np.vstack(X_train)).reshape(nr_train, maxlen, -1)\n",
    "X_val = scaler.transform(np.vstack(X_val)).reshape(nr_val, maxlen, -1)\n",
    "X_test = scaler.transform(np.vstack(X_test)).reshape(nr_test, maxlen, -1)\n",
    "print('Datenvorbereitung fertig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Überprüfen der Form der Numpy Arrays. '''\n",
    "print('Shape X_train:\\t' + str(X_train.shape))\n",
    "print('Shape X_val:\\t' + str(X_val.shape))\n",
    "print('Shape X_test:\\t' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelle bilden - pur CNN Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Modellaufbau des CNN Modells\n",
    "\n",
    "Zuerst wird ein reines CNN Modell erstellt. Dessen Performance wird danach mit einem mixed Modell aus CNN Layer und RNN Layern verglichen.\n",
    "\n",
    "TODO:\n",
    "* Importiere die notwendigen Layer\n",
    "* Definiere eine Modellstruktur \n",
    "* Finde eine gute Anzahl der Layer und der Filter/Knoten je Layer\n",
    "* Probiere also verschiedene Modellgrößen aus, um das beste Modell für die Aufgabe zu finden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Modellaufbau'''\n",
    "# Import der notwendigen Klassen und Funktionen\n",
    "TODO\n",
    "\n",
    "# Definition des Input_Shapes\n",
    "input_shape = (TODO, TODO)\n",
    "\n",
    "# Definition des Modells\n",
    "model = Sequential()\n",
    "\"\"\"\n",
    "*\n",
    "* TODO: \n",
    "*      Layers hinzufügen\n",
    "*     \n",
    "\"\"\"\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Modellkompilierung des CNN Modells\n",
    "TODO: \n",
    "* Wähle einen Optimierer aus (Adam, Nadam, RMSprop oder SGD) \n",
    "* Lege - falls notwendig - die Parameter des Optimiers fest, Lernrate o.ä.\n",
    "* Bestimme, welche Loss Funktion verwendet werden soll \n",
    "\n",
    "Hinweis:  \n",
    "Die Lernrate ist ein sehr wichtiger Hyperparameter, der viel Einfluss auf den Verlauf und Schnelligkeit des Trainings hat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modell kompilieren. '''\n",
    "# Optimizer festlegen\n",
    "optimizer = TODO\n",
    "\n",
    "# Einstellung für das spätere Training zum Kompilieren festlegen\n",
    "model.compile(optimizer=optimizer, loss=TODO, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Trainieren des CNN Modells\n",
    "\n",
    "TODO:\n",
    "* Wähle die Anzahl der Epochen  und die Batch_Size aus, für die das Modell trainiert werden soll. \n",
    "* Danach müssen die Trainingsinputs, -outputs, die batch_size, die Anzahl der Epochen sowie die Validierungsdaten bestimmt werden.\n",
    "\n",
    "Ausgabe: \n",
    "* Zwischenergebnisse je Epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Modell trainieren '''\n",
    "# Festlegung der Batch_Size und Anzahl der Epoche\n",
    "batch_size = TODO\n",
    "epochs = TODO\n",
    "\n",
    "# Durchführen des Trainings. Die Ergebnisse je Epoche werden in der History gespeichert. \n",
    "history_cnn = model.fit(TODO)\n",
    "\n",
    "# Modell in extra Variable speichern\n",
    "model_cnn = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelle validieren - CNN Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennzahlen fürs Training und Validierung:\n",
    "TODO:\n",
    "* Berechne den Loss und die Accuracy für das CNN Modell\n",
    "\n",
    "Tipp:\n",
    "* Nutze den evaluate Befehl mit den jeweils richtigen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kennzahlen (Loss und Accuracy Metrik) fürs Training beim CNN Modell:')\n",
    "print(model_cnn.TODO)\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) für Validierung beim CNN Modell:')\n",
    "print(model_cnn.TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trainingsverlauf plotten. \"\"\"\n",
    "train_acc = history_cnn.history['acc']\n",
    "val_acc = history_cnn.history['val_acc']\n",
    "train_loss = history_cnn.history['loss']\n",
    "val_loss = history_cnn.history['val_loss']\n",
    "epochs = range(1,len(train_acc) +1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_acc,'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc,'b', label='Validation accuracy')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(top=1.0)  # adjust the top leaving bottom unchanged\n",
    "plt.title('Loss Dense NN', fontsize = 16)\n",
    "plt.title('Accuracy', fontsize=16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(bottom=0.0)  \n",
    "plt.title('Loss Dense NN', fontsize = 16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelle bilden - CNN + RNN Modell\n",
    "Nun soll ein kombiniertes Modell erstellt werden. Bei diesem Modell sollen die Daten erst mittel CNN Layern verdichtet werden bevor danach ein RNN Schicht, also LSTM oder GRU angewendet wird. Die Performance dieses Modells soll danach mit dem des reinen CNN Modells verglichen werden.\n",
    "\n",
    "### 1. Modellaufbau des CNN + RNN Modells\n",
    "\n",
    "TODO:\n",
    "* Importiere die notwendigen Layer\n",
    "* Definiere eine Modellstruktur bestehend aus Convolutional und RNN Schichten\n",
    "* Finde eine gute Anzahl der Layer und der Filter/Knoten je Layer\n",
    "* Probiere also verschiedene Modellgrößen aus, um das beste Modell für die Aufgabe zu finden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modellaufbau '''\n",
    "# Import der notwendigen Layer\n",
    "TODO\n",
    "\n",
    "# Definition des Input_Shapes\n",
    "input_shape = (TODO, TODO)\n",
    "\n",
    "\n",
    "# Definition des Modells\n",
    "model = Sequential()\n",
    "\"\"\"\n",
    "*\n",
    "* TODO: \n",
    "*      Layers hinzufügen\n",
    "*     \n",
    "\"\"\"\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Modellkompilierung des CNN + RNN Modells\n",
    "TODO: \n",
    "* Wähle einen Optimierer aus (Adam, Nadam, RMSprop oder SGD) \n",
    "* Lege - falls notwendig - die Parameter des Optimiers fest, Lernrate, GradientClipping o.ä.\n",
    "* Bestimme, welche Loss Funktion verwendet werden soll\n",
    "\n",
    "Hinweise:  \n",
    "Die Lernrate ist ein sehr wichtiger Hyperparameter, der viel Einfluss auf den Verlauf und Schnelligkeit des Trainings hat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modell kompilieren. '''\n",
    "# Optimizer festlegen\n",
    "optimizer = TODO\n",
    "\n",
    "# Einstellung für das spätere Training zum Kompilieren festlegen\n",
    "model.compile(optimizer=optimizer, loss=TODO, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Modelltraining des CNN + RNN Modells\n",
    "\n",
    "TODO:\n",
    "* Wähle die Anzahl der Epochen und die Batch_Size aus, für die das Modell trainiert werden soll. \n",
    "* Danach müssen die Trainingsinputs, -outputs, die batch_size, die Anzahl der Epochen sowie die Validierungsdaten bestimmt werden.\n",
    "\n",
    "Ausgabe: \n",
    "* Zwischenergebnisse je Epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Modell trainieren '''\n",
    "# Festlegung der Batch_Size und Anzahl der Epoche\n",
    "batch_size = TODO\n",
    "epochs = TODO\n",
    "\n",
    "# Durchführen des Trainings. Die Ergebnisse je Epoche werden in der History gespeichert. \n",
    "history_rnn = model.fit(TODO)\n",
    "\n",
    "# Modell in extra Variable speichern\n",
    "model_rnn = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelle validieren - CNN + RNN Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennzahlen fürs Training und Validierung:\n",
    "TODO:\n",
    "* Berechne den Loss und die Accuracy für das CNN + RNN Modell\n",
    "\n",
    "Tipp:\n",
    "* Nutze den evaluate Befehl mit den jeweils richtigen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Bewertung des Trainings anhand der Valididierungsdaten mittels der Accuracy. '''\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) fürs Training beim CNN ü Modell:')\n",
    "print(model_rnn.TODO)\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) für Validierung beim GRU Modell:')\n",
    "print(model_rnn.TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trainingsverlauf plotten. \"\"\"\n",
    "train_acc = history_rnn.history['acc']\n",
    "val_acc = history_rnn.history['val_acc']\n",
    "train_loss = history_rnn.history['loss']\n",
    "val_loss = history_rnn.history['val_loss']\n",
    "epochs = range(1,len(train_acc) +1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_acc,'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc,'b', label='Validation accuracy')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(top=1.0)  # adjust the top leaving bottom unchanged\n",
    "plt.title('Accuracy SimpleRNN', fontsize=16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(bottom=0.0)  \n",
    "plt.title('Loss SimpleRNN', fontsize = 16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelle validieren - Vergleich CNN und CNN + RNN\n",
    "TODO:\n",
    "* Berechne den Loss und die Accuracy für die beiden Modelle jeweils für Training und Validierung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kennzahlen (Loss und Accuracy Metrik) fürs Training beim CNN Modell:')\n",
    "print(model_cnn.TODO)\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) für Validierung beim CNN Modell:')\n",
    "print(model_cnn.TODO)\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) fürs Training beim CNN + RNN Modell:')\n",
    "print(model_rnn.TODO)\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) für Validierung beim CNN + RNN Modell:')\n",
    "print(model_rnn.TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell auswählen\n",
    "Wähle ein finales Modell, also model_cnn oder model_rnn, aus, dass nun getestet werden soll.   \n",
    "Dieses Modell wird in der Variable model gespeichert, mit der im Schritt 6. weitergearbeite wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modell testen & anwenden\n",
    "\n",
    "Führen Sie diesen Schritt erst aus, wenn Sie mit Ihrem Modell zufrieden sind.  \n",
    "\n",
    "Der Test eines Modells soll ermitteln, wie gut das Modell übertragbar und generalisierbar ist.  \n",
    "Wenn alle Modelle direkt getestet, wird einfach nur das Modell ausgewählt, das am Besten zum Testdatensatz passt. Dadurch bekommt man aber nicht das Modell, das das Problem grundsätzlich am Besten löst. Es gibt somit ein Overfitting bzgl. den Testdaten.\n",
    "\n",
    "TODO:\n",
    "* Berechne den Loss und die Accuracy anhand der Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Bewertung des Trainings anhand der Valididierungsdaten mittels der Accuracy. '''\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) bei Testen:')\n",
    "model.TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Modell anhand Testdaten bewerten\"\"\"\n",
    "y_test_pred = (model.predict(X_test)>0.5).astype(\"int32\")[:, -1, :]\n",
    "# Berechne Genauigkeit auf den Testdaten\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Berechne den F1-Score auf den Testdaten\n",
    "f1score_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für den Test:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_test, 4)))\n",
    "print('F1-Score: \\t' + str(round(f1score_test, 4)))\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "plt.grid()\n",
    "plt.title('Konfusionsmatrix auf Testdaten')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DLfsP)",
   "language": "python",
   "name": "python-dlfsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
