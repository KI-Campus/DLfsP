{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLfsP RNN Improvements am Beispiel PSF\n",
    "Kurs Deep Learning für sequentielle Prozessdaten\n",
    "\n",
    "#### In diesem Notebook sollen verschiedene Techniken, wie Bidirectional Layers und Callbacks,  ausprobiert werden.  \n",
    "\n",
    "__Achtung: Bei dieser Übung geht es nicht darum, dass Problem möglichst gut zu lösen. Ziel diese Übung ist es auszuprobieren, welche Effekte gewisse Elemente wie EarlyStopping, LearningRateScheduler & Co. auf den Trainingsprozess haben.__  \n",
    "\n",
    "Linearführungen und Profilschienenführungen sind für einen nicht unbedeutenden Teil der Ausfälle bei Werkzeugmaschinen.\n",
    "Typische Fehlerfälle die dabei auftreten sind Mangelschmierungen, Pittings an Laufbahnen oder an den Wälzkörpern. In diesem Beispiel gibt es Daten von Normalfahrten und vom Zustand Pitting.  \n",
    "\n",
    "Während der Versuche wurde mittels einem 3-achsigen MEMS-Sensor Daten vom Wagen aufgenommen. \n",
    "Für diese Aufgabe wurde nur die Beschleunigung in Verfahrrichtung (Acc_X) verwendet. Grundsätzlich handelt es sich um die gleichen Daten wie beim SimpleRNN, allerdings wurden nun längere Zeitreihen mit einer höheren Genauigkeit aufgenommen. Ziel ist die Erkennung, also Klassifikation nach dem Zustand ('Status'), dazu soll sowohl ein Modell mittels LSTM und eins mittels GRU gebildet werden. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-Mining-Prozess:\n",
    "![Daten erfassen -> Daten erkunden -> Daten vorbereiten -> Modelle bilden -> Modelle validieren -> Modell testen & anwenden](Prozess_Modellentwicklung_v2.png \"model development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import der wichtigsten Pakete. '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "#Einstellungen für die Grafikausgabe\n",
    "style = 'seaborn-whitegrid'\n",
    "plt.style.use(style)\n",
    "plt.rcParams.update({'font.size': 14})  # Schriftgröße aller Textzeichen im Graphen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Überprüfe, ob TensorFlow installiert ist und die GPU oder die CPU nutzt. '''\n",
    "print('TF version: ' + tf.__version__)\n",
    "if tf.test.is_built_with_gpu_support():\n",
    "    if len(tf.config.list_physical_devices('GPU'))==0:\n",
    "         print('Achtung, TensorFlow nutzt gerade die CPU und nicht die GPU!')\n",
    "    else:\n",
    "        print('Default GPU Device: {}'.format(tf.config.list_physical_devices('GPU')))\n",
    "        # GPU-Memory-Management:\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.compat.v1.Session(config=config)\n",
    "else:\n",
    "    print('TensorFlow CPU version active')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen my_seed=\n",
    "\n",
    "Damit Ergebnisse Reproduzierbar sind, müssen mehrere Seeds für Zufallszahlengeneratoren gesetzt werden. \n",
    "\n",
    "AUSGABE:\n",
    "* Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Setzen von Seeds, um Reproduzierbarkeit zu ermöglichen. '''\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))\n",
    "\n",
    "# Seeds für diverse Zufallszahlengeneratoren setzen \n",
    "os.environ['PYTHONHASHSEED']=str(my_seed)\n",
    "tf.random.set_seed(my_seed)\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten erfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PSF_Pitting.csv') \n",
    "print('Daten erfolgreich importiert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ersten Datensätze als Beispiel\"\"\"\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Statistische Beschreibung Datensatz\"\"\"\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einige Zyklen plotten\n",
    "cycles=[]\n",
    "cycles = random.sample(df['run_ID'].drop_duplicates().to_list(), 3)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.ylabel('Beschleunigung in X')\n",
    "for c in cycles:\n",
    "    status = df[df['run_ID']==c].reset_index().loc[0,'Status']\n",
    "    plt.plot(df[df['run_ID']==c]['time_ms'],df[df['run_ID']==c]['Acc_X'],label='Run '+str(c) + ' Status ' + str(status))\n",
    "\n",
    "plt.xlabel('Zeit in ms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aufteilung in X und y\"\"\"\n",
    "# Maximale Zykluslänge\n",
    "maxlen = df['run_ID'].value_counts().max()    \n",
    "\n",
    "# Aufteilung X und y Daten als DataFrames\n",
    "y_df = df[['Status','run_ID']]\n",
    "X_df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Umwandeln der DataFrames in numpy arrays und group by run_ID\"\"\"\n",
    "g = X_df.groupby('run_ID').cumcount()\n",
    "X = (X_df.set_index(['run_ID',g])\n",
    "     .unstack()\n",
    "     .stack().groupby(level=0)\n",
    "     .apply(lambda x: x['Acc_X'].values)\n",
    "     .to_numpy())\n",
    "g = y_df.groupby('run_ID').cumcount()\n",
    "y = (y_df.set_index(['run_ID',g])\n",
    "     .unstack()\n",
    "     .stack().groupby(level=0)\n",
    "     .apply(lambda x: np.rint(x.sum()/len(x)))\n",
    "     .to_numpy().astype(\"int32\"))\n",
    "\n",
    "print('Shapes der numpy Arrays X und y:')\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Auffüllen der ungleichen Messreihen'''\n",
    "# Auffüllen mit führenden Nullen, damit die Zeitreihen die gleiche Länge haben\n",
    "X_pre = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=maxlen, padding='pre', dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Aufteilen in Trainings-, Validierungs und Testdaten. \"\"\"\n",
    "# Festlegen des Anteils an Test- und Validierungsdaten\n",
    "test_split = 0.2\n",
    "validation_split = 0.2\n",
    "\n",
    "# Aufteilung der Daten\n",
    "# Testdaten abspalten# Aufteilung der Daten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pre, y, \n",
    "                                                    test_size=test_split, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=my_seed)\n",
    "\n",
    "# Aufsplitten in Trainings- und Validierungsdaten\n",
    "X_train, X_val, y_train ,y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=validation_split, \n",
    "                                                  shuffle=True, \n",
    "                                                  random_state=my_seed)\n",
    "\n",
    "nr_train=len(X_train)\n",
    "nr_val=len(X_val)\n",
    "nr_test=len(X_test)\n",
    "print(nr_train, \"Training sequences\")\n",
    "print(nr_val, \"Validation sequences\")\n",
    "print(nr_test, \"Test sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Daten normalisieren. \"\"\"\n",
    "# Importieren und Anlernen des Scalers (d.h. Scaler lernt Mittelwerte und Standardabweichungen der Features)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Normierung der Daten mit den gelernten Paramatern und gleichzeitiges Formatieren\n",
    "X_train = scaler.transform(X_train).reshape(nr_train, maxlen, -1)\n",
    "X_val = scaler.transform(X_val).reshape(nr_val, maxlen, -1)\n",
    "X_test = scaler.transform(X_test).reshape(nr_test, maxlen, -1)\n",
    "print('Datenvorbereitung fertig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Überprüfen der Form der Numpy Arrays. '''\n",
    "print('Shape X_train:\\t' + str(X_train.shape))\n",
    "print('Shape X_val:\\t' + str(X_val.shape))\n",
    "print('Shape X_test:\\t' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelle bilden - LSTM Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Modellaufbau des LSTM Modells\n",
    "\n",
    "Ein einfaches LSTM Modell ist bereits vorgegeben. Die folgenden TODOS werden am besten nacheinander ausgeführt bzw. jeweils einzeln. So wird der jeweilige Effekt am deutlichsten sichtbar.\n",
    "\n",
    "TODO:\n",
    "* Mache aus dem einfachen LSTM Modell ein Bidirectional LSTM Modell\n",
    "* Teste den Einfluss von Dorpout auf das Modell, probiere dazu unterschiedliche Dropout Rates aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Modellaufbau'''\n",
    "# Import der notwendigen Klassen und Funktionen\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Definition des Input_Shapes\n",
    "input_shape = (213, 1)\n",
    "\n",
    "# Definition des Modells\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=input_shape, return_sequences=True))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Modellkompilierung des LSTM Modells\n",
    "TODO: \n",
    "* Wähle einen Optimierer aus (Adam, Nadam, RMSprop oder SGD) \n",
    "* Teste unterschiedliche Learning Rates, bspw. 1e-2, 1e-4 u.ä. \n",
    "* Verwende anstatt einer festen Learning Rate den Learning Rate Scheduler Exponential Decay. Probier verschiedene Werte für die Initial Learning Rate (1e-2, 1e-3 u.ä.), unterschiedliche decay_rates und decay_steps aus. \n",
    "\n",
    "\n",
    "Hinweise:  \n",
    "* Wird der vorimplementierte Learning Rate Scheduler verwendet, dann entspricht ein Iterationsschritt - also ein decay_step - der Ausführung eines Batches. Die Anzahl der Batches ist somit gleich der Anzahl der Iterationsschritte je Epoche.\n",
    "* Bei einer Batch_size von 32 ergeben sich bei diesem Datensatz nur 7 Batches je Epoche. Daher sollte die Decay_steps nicht zu groß gewählt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Modell kompilieren. '''\n",
    "# Optimizer festlegen\n",
    "\n",
    "optimizer = TODO\n",
    "\n",
    "# Einstellung für das spätere Training zum Kompilieren festlegen\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Trainieren des LSTM Modells\n",
    "\n",
    "TODO:\n",
    "* Baue den Callback Early Stopping ein. Teste dabei verschieden Werte für die Patience.\n",
    "* Die Verwendung von TensorBoard ist auch zu empfehlen, da die verschiedenen Trainingsverläufe auch noch im Nachgang vergleichbar sind. \n",
    "* Gerne auch mal den CallbackReduceLROnPlateau ausprobieren. Allerdings nicht gleichzeit mit dem Exponential Decay!\n",
    "\n",
    "Ausgabe: \n",
    "* Zwischenergebnisse je Epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Modell trainieren '''\n",
    "# Festlegung der Batch_Size und Anzahl der Epoche\n",
    "batch_size = 32\n",
    "epochs = 250\n",
    "\n",
    "\n",
    "# Durchführen des Trainings. Die Ergebnisse je Epoche werden in der History gespeichert. \n",
    "history = model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(X_val, y_val), shuffle=True, callbacks=TODO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelle validieren - LSTM Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennzahlen fürs Training und Validierung:\n",
    "TODO:\n",
    "* Übergebe jeweils die Trainingsdaten bzw. Validierungsdaten dem evaluate Befehl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kennzahlen (Loss und Accuracy Metrik) fürs Training beim Dense Modell:')\n",
    "print(model.evaluate(X_train, y_train))\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) für Validierung beim Dense Modell:')\n",
    "print(model.evaluate(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trainingsverlauf plotten. \"\"\"\n",
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(train_acc) +1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_acc,'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc,'b', label='Validation accuracy')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(top=1.0)  # adjust the top leaving bottom unchanged\n",
    "\n",
    "plt.title('Accuracy LSTM', fontsize=16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlim((0, max(epochs)))\n",
    "plt.ylim(bottom=0.0)  \n",
    "plt.title('Loss LSTM', fontsize = 16)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modell testen & anwenden\n",
    "\n",
    "Führen Sie diesen Schritt erst aus, wenn Sie mit Ihrem Modell zufrieden sind.  \n",
    "\n",
    "Der Test eines Modells soll ermitteln, wie gut das Modell übertragbar und generalisierbar ist.  \n",
    "Wenn Sie alle Modelle direkt testen, wählen Sie nur das Modell aus, was am Besten zum Testdatensatz passt. Aber nicht welches das Problem grundsätzlich am Besten löst. Sie Overfitten somit den Testdatensatz.\n",
    "\n",
    "TODO:\n",
    "* Übergebe die Testdaten dem evaluate Befehl zur finalen Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Bewertung des Trainings anhand der Valididierungsdaten mittels der Accuracy. '''\n",
    "print('Kennzahlen (Loss und Accuracy Metrik) bei Testen:')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Modell anhand Testdaten bewerten\"\"\"\n",
    "y_test_pred = (model.predict(X_test)>0.5).astype(\"int32\")\n",
    "# Berechne Genauigkeit auf den Testdaten\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Berechne den F1-Score auf den Testdaten\n",
    "f1score_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Ausgabe der Modellgenauigkeit\n",
    "print('Ergebnis für den Test:')\n",
    "print('Accuracy: \\t' + str(round(accuracy_test, 4)))\n",
    "print('F1-Score: \\t' + str(round(f1score_test, 4)))\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "plt.grid()\n",
    "plt.title('Konfusionsmatrix auf Testdaten')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DLfsP)",
   "language": "python",
   "name": "python-dlfsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
